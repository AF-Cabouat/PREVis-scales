---
title: "Reliability of combinations (models)"
author: "Anne-Flore Cabouat"
date: "2024-01-22"
output: html_document
---

```{r oursetup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Get the current R Markdown notebook file path and the grandparent folder
get_current_rmd_path <- function() {
  if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable()) {
    # When running interactively in RStudio
    return(rstudioapi::getActiveDocumentContext()$path)
  } else if (requireNamespace("knitr", quietly = TRUE)) {
    # When knitting the document
    return(knitr::current_input(dir = TRUE)) 
  } else {
    stop("Cannot determine the current R Markdown file path.")
  }
}

current_rmd_path <- get_current_rmd_path()
my_dir <- dirname(dirname(current_rmd_path))


#### OPTIONAL: manual setting of directory
#my_dir <- "your_data_directory" #eg: "C:/Absolute_path_to_git/PREVis-scales/research code/Replication - PREVis development figures"

# We create the output folders if they don't exist
if (!dir.exists(file.path(my_dir, "Data_Analysis"))) {
  dir.create(file.path(my_dir, "Data_Analysis"), recursive = TRUE)
}

# We set our working directory to the Data_Analysis folder so that all outputs are saved there
my_wd <- file.path(my_dir, "Data_Analysis")
setwd(my_wd)
knitr::opts_knit$set(root.dir = file.path("..", "Data_Analysis"))

# Print the current working directory to verify
print(getwd())

```

## Librairies

```{r librairies}

load_and_install_libraries <- function(libraries) {
  for (lib in libraries) {
    if (!require(lib, character.only = TRUE)) {
      install.packages(lib)
      library(lib, character.only = TRUE)
    }
  }
}

required_libraries <- c("psych", "mice", "mifa", "corrplot", "knitr", "lavaan", "dplyr", "tibble", "RColorBrewer")
load_and_install_libraries(required_libraries)

if (!require("misty", character.only = TRUE)) {
  stop("misty package is not installed. Open the first notebook ('Reproduce1') in this directory and run the first chunk called 'r libraries' to install it.")
} else {
  library("misty", character.only = TRUE)
  if (packageVersion("misty") != "0.6.0") {
    stop("misty package version is not 0.6.0. Open the first notebook ('Reproduce1') in this directory and run the first chunk called 'r libraries' TWICE to uninstall the current version and replace it with the correct version.")
  }
}
```
## Functions
```{r functions}

make_corrM <- function(d, order = NULL, nb_fa = 4){
  # Multiple imputation using Fully Conditional Specification (FCS) implemented by the MICE algorithm as described in Van Buuren and Groothuis-Oudshoorn (2011) doi:10.18637/jss.v045.i03
  #run MICE and generate covariance matrix with with mifa package
  mi <- invisible(mifa(
  data      = d, 
  n_pc      = nb_fa, #factors estimates
  ci        = "fieller", #confidence interval method
  print     = FALSE,
  m = 5 #number of MICE iterations
  ))
  
  corr_MICE <- cov2cor(mi$cov_combined)
  
  if (length(order)>0){
    corrM_reorder <- corr_MICE[order, order]
    corr_MICE <- corrM_reorder
  }
  
  # corrM <- corFiml(d)
  return(corr_MICE)
}

corrM_to_file <- function (d, file, order = NULL, nb_fa = 4){
  # export correlation matrix
  corrM <- make_corrM(data, order = order, nb_fa = nb_fa)
  
  num_items <- ncol(d)
  ## as csv
  write.csv(corrM,file=paste("generatedData-CFA/correlations/", file, ".csv", sep=""))
  # as pdf
  pdf(paste("generatedPlots-CFA/correlations/", file, ".pdf", sep=""), height=15, width=15)
  plot <- corrplot(corrM,
          # type = 'lower', #only lower half
          tl.srt = 30, #rotate text labels
          method="color",
          col = COL2('RdYlBu'),
          order="original",
          addrect = 4,
          tl.col="black", tl.cex = 1.3, # Text label color and size
          addCoef.col = "white", number.cex = 1, # Add coefficient of correlation and size
          )
  print(plot) # keeps printing the full correlation matrix as output
  dev.off()
  return("Corr Matrix export done.")
}
  

# Applicability of EFA

## Bartlett test of sphericity - from TH
bartlettTest <- function(corrMatrix,data){
  bart <- cortest.bartlett(corrMatrix, n = nrow(data))
  if(bart[2]>0.05) cat("WARNING the p value is above 0.05") else cat("The p value is below 0.05. We are good to continue.")
  cat("\n\n")
  print(bart)
  return(bart)
}

##KMO to complement Bartlett - from TH
KMOTest <- function(corrMatrix){
  kmo <- KMO(corrMatrix)
  cat(paste("The overall measure of sampling adequacy is: ",kmo[1]))
  cat("\n\n")
  if(kmo[1]<.7) cat("WARNING the sampling adequacy has dropped below 0.7") else cat("The sampling adequacy is above 0.7. We are generally good.")
  cat("\n\n")
  return(kmo)
}

# Missing values

missingTest <- function(na_percent, mcar_pvalue){
  if (na_percent<5 & mcar_pvalue<=.05){
      cat("Data is MCAR and less than 5% missing data, which is negligible. We are good to continue.")
  } else if (na_percent<5 & mcar_pvalue>.05){
      cat("Data is NOT MCAR but less than 5% missing data, which is negligible. We are good to continue.")
  } else if(na_percent>=5 & mcar_pvalue>.05) {
      cat("WARNING missing data is not negligible (> 5%) AND missing data is NOT MCAR. Further investigation is needed.")
    }else if (na_percent>=5 & na_percent<40 & mcar_pvalue<=.05){
      cat("Data is MCAR but more than 5% missing data. Use imputation / likelihood methods.")
    }  else {
      cat("40% or more missing data and / or something is wrong.")
    }}


# Parallel analysis for each group

parallelAnalysis <- function(corrMatrix, observations = nrow(the_data), file_suffix){
  pdf(paste(paste("generatedPlots-EFA/ScreePlot-",file_suffix,sep=""),'.pdf'), width=8, height=4)
  parallel <- fa.parallel(corrMatrix, n.obs=observations, fa="fa", n.iter=100, main="Scree plots with parallel analysis", error.bars = TRUE)
  print(parallel)
  dev.off() 
  cat("\n\n")
}

stimulus_data_test <- function(the_data, the_letter){
  ## Here wwe run test on the data
  ### Shapiro Wilk’s test (P-values < 0.05 indicate not normal)
  cat(paste("\n=================\n NORMALITY in", the_letter, "\n"))

  cat(paste("\n #### Shapiro in", the_letter, "\n"))
  mapply(shapiro.test, the_data)

  ### Multivariate normality
  # To say the data are multivariate normal: 
  # • z-kurtosis < 5 (Bentler, 2006) and the P-value should be ≥ 0.05.
  # • the plot should also form a straight line (Arifin, 2015).

  cat(paste("\n #### Multivariate normality in", the_letter, "\n"))
  mardia(the_data)

  cat(paste("\n=================\n MISSING DATA IN in", the_letter, "\n"))
  ### Missing data

  cat("#### Little's test for MCAR\n")
  #test MCAR
  MCAR <- na.test(the_data)
  mcar_p <- MCAR[["result"]][["pval"]]
  
  cat("\n#### Amount of missing data\n")
  nb_obs <- nrow(the_data)*ncol(the_data)
  na_amount <- sum(is.na(the_data))/nb_obs*100
  cat(paste(as.numeric(na_amount)), "% of data is missing\n\n")
  
  missingTest(na_amount, mcar_p)


### Multiple Imputation for missing values
  cat(paste("\n Multiple Imputation for missing values in", the_letter, "\n"))
  corr_MICE <- make_corrM(the_data, nb_fa = 4)

  cat(paste("\n=================\n FACTORABILITY in", the_letter, "\n"))
  
  ####  Bartlett’s test of sphericity
  # An objective test of the factorability of the correlation matrix is Bartlett’s (1954) test of sphericity, which statistically tests the hypothesis that the correlation matrix contains ones on the diagonal and zeros on the off-diagonals. Hence, that it was generated by random data. This test should produce a statistically significant chi-square value to justify the application of EFA.
  # If the p-value from Bartlett’s Test of Sphericity is lower than our chosen significance level (common choices are 0.10, 0.05, and 0.01), then our dataset is suitable for a data reduction technique.
  cat(paste("\n #### Bartlett in", the_letter, "\n"))
  bartlettTest(corr_MICE, the_data)

  ####  KMO
  # Large sample sizes make the Bartlett test sensitive to even trivial deviations from randomness, so its results should be supplemented with a measure of sampling adequacy. The Kaiser-Meyer-Olkin (KMO; Kaiser, 1974) measure of sampling adequacy is the ratio of correlations and partial correlations that reflects the extent to which correlations are a function of the variance shared across all variables rather than the variance shared by particular pairs of variables. KMO values range from 0.00 to 1.00 and can be computed for the total correlation matrix as well as for each measured variable.
  # - KMO values ≥.70 are desired
  # - KMO values ≤.50 are generally considered unacceptable
  cat(paste("\n #### KMO in", the_letter, "\n"))
  KMOTest(corr_MICE)


  
  cat(paste("\n=================\n RELIABILITY with 4 factors in", the_letter, "\n"))
  ## omega for 4 factors and alpha from data

  om <- omega(corr_MICE, 4, n.obs=nrow(the_data), rotate="Promax")
  print(paste('Alpha:', om$alpha))
  print(paste('G.6:', om$G6))
  print(paste('Omega H asymptotic:', om$omega_h))
  print(paste('Omega Total:', om$omega.tot))
  #summary(om)


  ### Number of factors to retain
  # Measurement specialists have conducted simulation studies and concluded that parallel analysis and MAP are the most accurate empirical estimates of the number of factors to retain and that scree is a useful subjective adjunct to the empirical estimates. Unfortunately, no method has been found to be correct in all situations, so it is necessary to employ multiple methods and carefully judge each plausible solution to identify the most appropriate factor solution.

  # parallelAnalysis(corr_MICE, observations=nb_obs, "All")
}

select_all_variables <- function (dataset, col_list) {
  dataset %>% select(all_of(unlist(col_list)))
}

```

## Multigroup CFA using lavaan

```{r prepare model and data filters}

stimuli_letters <- list("A","B","C","D","E","F")

#we retrieve our model from EFA conducted on all data

## Full model: all items with loadings > 0.32 and no cross-loadings
full_Readability_factors <- list(
  understand = c('obvious', 'meanOveral', 'confid', 'represent', 'understandEasi', 'understandQuick', 'meanElem'),
  layout = c('crowd', 'messi', 'distract', 'organiz'),
  dataRead = c('find', 'identifi', 'valu', 'inform', 'readabl'),
  dataFeat = c('visibl', 'see')
)

# Create a vector of column names to keep for the model with all included items
full_columns_to_keep <- unlist(full_Readability_factors)

# Function to convert a factor list to the required string format
factor_to_string <- function(factor_name, factor_list) {
  paste(factor_name, " =~ ", paste(factor_list, collapse = " + "))
}

```
## Load data

```{r load data}
setwd(my_wd)

data_dir <- file.path(my_dir, "Data")
file_path <- file.path(data_dir, "ratings-stimulus.csv")
my_data <- read.csv(file_path, encoding="UTF-8")
grp_data <- subset(my_data, select = -c(seed))
data <- subset(grp_data, select = -c(stimulus))

# and make directories if needed

if (!dir.exists("generatedData-CFA/correlations/")) {
  dir.create("generatedData-CFA/correlations/", recursive = TRUE)
}
if (!dir.exists("generatedData-CFA/reliability/to aggregate/")) {
  dir.create("generatedData-CFA/reliability/to aggregate/", recursive = TRUE)
}

if (!dir.exists("generatedPlots-CFA/correlations/")) {
  dir.create("generatedPlots-CFA/correlations/", recursive = TRUE)
}

```

## Descriptive statistics - Check minimum/maximum values per item, and screen for missing values
```{r data overview}

setwd(my_wd)

cat("\n\n==========================================\n
    ==========================================\n
    ==========================================\n")
cat("\n\n BEFORE ITEM REDUCTION\n\n")
cat("==========================================\n
    ==========================================\n
    ==========================================\n\n")

describe(data)
response.frequencies(data)
nb_obs <- nrow(data)
cat("\n Sample size:")
print(nb_obs)

#corr Matrix with all possible items
data_all_factors <- data %>% select(all_of(full_columns_to_keep))
corrM <- make_corrM(data_all_factors, nb_fa = 4)

num_items <- ncol(data_all_factors)
## as csv
write.csv(corrM,file="generatedData-CFA/correlations/factors-all_items-corr.csv")
# as pdf
this_file <- "generatedPlots-CFA/correlations/factors-all_items-corr.pdf"
pdf(this_file, height=15, width=15)
plot <- corrplot(corrM,
        # type = 'lower', #only lower half
        tl.srt = 30, #rotate text labels
        method="color",
        col = COL2('RdYlBu'),
        order="original",
        addrect = 4,
        tl.col="black", tl.cex = 1.3, # Text label color and size
        addCoef.col = "white", number.cex = 1, # Add coefficient of correlation and size
        )
dev.off()

```

# Factor by factor (full, non-reduced) alpha reliability and item-total correlations
```{r item-total reliability for each full factor}
setwd(my_wd)

list_alpha_dfs <- list()

for (factor in names(full_Readability_factors)) {
  cat(paste("\n ======================\n Individual full factor reliability for", factor, "\n (omega and alpha) \n"))
  this_factor_columns <- unlist(full_Readability_factors[[factor]])
  factor_data <- data %>% select(all_of(this_factor_columns))
  
  this_filename = paste(factor, "-corr", sep = "")
  corrM_to_file(factor_data, file = this_filename, this_factor_columns)
  
  # factor-wise reliability
  # omega
  nb_obs <- nrow(factor_data)
  corrM <- make_corrM(factor_data, nb_fa = 1)
  om <- omega(corrM, n.obs = nb_obs, 1)
  summary(om)
  
  #alpha
  alpha_values <- psych::alpha(factor_data)
  
  cat("Alpha raw:")
  print(alpha_values$total$raw_alpha)
  print(alpha_values$total)
  
  # output df
  factor_alpha_df <- alpha_values$total
  factor_alpha_df$omega_tot <- om$omega.tot
  write.csv(factor_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-full_data-reliability.csv", sep = ""))

  # factor-wise reliability for each stimulus
  for (letter in stimuli_letters){
    the_data <- filter(grp_data, stimulus == letter)
    stimulus_factor_data <- the_data %>% select(all_of(this_factor_columns))
    
    # omega
    nb_obs <- nrow(stimulus_factor_data)
    corrM <- make_corrM(stimulus_factor_data, nb_fa = 1)
    om <- omega(corrM, n.obs = nb_obs, 1)
    
    # alpha
    alpha_values <- psych::alpha(stimulus_factor_data)
    
    # output df
    factor_stimulus_alpha_df <- alpha_values$total
    factor_stimulus_alpha_df$omega_tot <- om$omega.tot
    write.csv(factor_stimulus_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",letter,"-full_data-reliability.csv", sep =""))
  }
  
  cat("Alpha items:")
  print(alpha_values$alpha.drop)
  
  # Extract the row names
  row_names <- gsub(paste(factor, "\\."), "", rownames(alpha_values$alpha.drop))
  
  # Modify the row names in the data frame and add the "Factor" column
  alpha_values$alpha.drop <- cbind(Factor = factor, alpha_values$alpha.drop)
  rownames(alpha_values$alpha.drop) <- row_names
  
  # Add the data frame to the list
  list_alpha_dfs[[factor]] <- alpha_values$alpha.drop
}

# Combine all item information dataframes into one table and export it
combined_df <- do.call(rbind, list_alpha_dfs)
write.csv(combined_df,file=("generatedData-CFA/items_scale_reliability_per_factor.csv"))


# Print the combined data frame
print(combined_df)

```


# Reliability on aggregated data for factors with selected items
```{r reliability of each sub-scale (each factor) for model_1}
setwd(my_wd)

cat("\n\n==========================================\n")
cat("==========================================\n")
cat("\n \n AFTER ITEM REDUCTION \n \n")
cat("==========================================\n")
cat("==========================================\n\n")
#### RUN THE NOTEBOOK ONCE PER MODEL ####


cat("\n\n==========================================\n")
cat("==========================================\n")
cat("==========================================\n")
cat("\n \n MODEL 1 \n \n")
cat("==========================================\n")
cat("==========================================\n")
cat("==========================================\n\n")

this_model <- "Model_1"
## best items selected on factor loadings only
Readability_factors <- list(
  understand = list("obvious","meanOveral","confid"),
  layout = list("crowd", "messi","distract"),
  dataRead = list("find","identifi","valu"),
  dataFeat = list("visibl","see")
)

# Create a vector of column names to keep for the model with selected items
columns_to_keep <- unlist(Readability_factors)

#corr Matrix with selected items
data_reduced_factors <- data %>% select(all_of(columns_to_keep))

corrM <- make_corrM(data_reduced_factors, nb_fa = 4)

num_items <- ncol(data_all_factors)
## as csv
write.csv(corrM,file=paste("generatedData-CFA/correlations/factor-", this_model, "-selected_items-corr.csv", sep =""))
# as pdf
this_file <- paste("generatedPlots-CFA/correlations/factor-", this_model,"-selected_items-corr.pdf", sep="")
pdf(this_file, height=15, width=15)
plot <- corrplot(corrM,
        # type = 'lower', #only lower half
        tl.srt = 30, #rotate text labels
        method="color",
        col = COL2('RdYlBu'),
        order="original",
        addrect = 4,
        tl.col="black", tl.cex = 1.3, # Text label color and size
        addCoef.col = "white", number.cex = 1, # Add coefficient of correlation and size
        )
dev.off()

## Create the model from list Readability_factors
# Apply the function to each element of the list
formatted_strings <- sapply(names(Readability_factors), function(factor_name) {
  factor_to_string(factor_name, Readability_factors[[factor_name]])
})

# Combine the strings into a single string
model_string <- paste(formatted_strings, collapse = '\n')

# Print the final string
cat(model_string)


for (factor in names(Readability_factors)){
  cat(paste("\n ======================\n Individual factor reliability on selected items for", this_model, "-", factor, "\n (omega and alpha) \n"))
  factor_data <- data %>% select(all_of(unlist(Readability_factors[[factor]])))
  
  # reliability
  
  # omega
  nb_obs <- nrow(factor_data)
  corrM <- make_corrM(factor_data, nb_fa = 1)
  om <- omega(corrM, n.obs = nb_obs, 1) #https://personality-project.org/r/psych/HowTo/omega.pdf
  summary(om)

  # alpha
  alpha_values <- psych::alpha(factor_data)
  cat("Alpha raw:")
  print(alpha_values$total$raw_alpha)
  print(alpha_values$total)

  # output df
  factor_alpha_df <- alpha_values$total
  factor_alpha_df$omega_tot <- om$omega.tot
  write.csv(factor_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-reliability.csv"))

  # factor-wise reliability for each stimulus
  for (letter in stimuli_letters){
    the_data <- filter(grp_data, stimulus == letter)
    stimulus_factor_data <- the_data %>% select(all_of(unlist(Readability_factors[[factor]])))
    
    # omega
    nb_obs <- nrow(stimulus_factor_data)
    corrM <- make_corrM(stimulus_factor_data, nb_fa = 1)
    om <- omega(corrM, n.obs = nb_obs, 1)
    
    # alpha
    alpha_values <- psych::alpha(stimulus_factor_data)
    
    # output df
    factor_stimulus_alpha_df <- alpha_values$total
    factor_stimulus_alpha_df$omega_tot <- om$omega.tot
    write.csv(factor_stimulus_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-",letter,"-reliability.csv", sep =""))
  }
}

```

```{r reliability of each sub-scale (each factor) for model_2}
setwd(my_wd)

cat("\n\n==========================================\n")
cat("==========================================\n")
cat("==========================================\n")
cat("\n \n MODEL 2 \n \n")
cat("==========================================\n")
cat("==========================================\n")
cat("==========================================\n\n")

this_model <- "Model_2"
## best items selected on reliability measures only
Readability_factors <- list(
  understand = list("understandEasi","represent","understandQuick"),
  layout = list("messi", "organiz","crowd"),
  dataRead = list("inform","identifi","find"),
  dataFeat = list("visibl","see")
)

# Create a vector of column names to keep for the model with selected items
columns_to_keep <- unlist(Readability_factors)

#corr Matrix with selected items
data_reduced_factors <- data %>% select(all_of(columns_to_keep))

corrM <- make_corrM(data_reduced_factors, nb_fa = 4)

num_items <- ncol(data_all_factors)
## as csv
write.csv(corrM,file=paste("generatedData-CFA/correlations/factor-", this_model, "-selected_items-corr.csv", sep =""))
# as pdf
this_file <- paste("generatedPlots-CFA/correlations/factor-", this_model,"-selected_items-corr.pdf", sep="")
pdf(this_file, height=15, width=15)
plot <- corrplot(corrM,
        # type = 'lower', #only lower half
        tl.srt = 30, #rotate text labels
        method="color",
        col = COL2('RdYlBu'),
        order="original",
        addrect = 4,
        tl.col="black", tl.cex = 1.3, # Text label color and size
        addCoef.col = "white", number.cex = 1, # Add coefficient of correlation and size
        )
dev.off()

## Create the model from list Readability_factors
# Apply the function to each element of the list
formatted_strings <- sapply(names(Readability_factors), function(factor_name) {
  factor_to_string(factor_name, Readability_factors[[factor_name]])
})

# Combine the strings into a single string
model_string <- paste(formatted_strings, collapse = '\n')

# Print the final string
cat(model_string)


for (factor in names(Readability_factors)){
  cat(paste("\n ======================\n Individual factor reliability on selected items for", this_model, "-", factor, "\n (omega and alpha) \n"))
  factor_data <- data %>% select(all_of(unlist(Readability_factors[[factor]])))
  
  # reliability
  
  # omega
  nb_obs <- nrow(factor_data)
  corrM <- make_corrM(factor_data, nb_fa = 1)
  om <- omega(corrM, n.obs = nb_obs, 1) #https://personality-project.org/r/psych/HowTo/omega.pdf
  summary(om)

  # alpha
  alpha_values <- psych::alpha(factor_data)
  cat("Alpha raw:")
  print(alpha_values$total$raw_alpha)
  print(alpha_values$total)

  # output df
  factor_alpha_df <- alpha_values$total
  factor_alpha_df$omega_tot <- om$omega.tot
  write.csv(factor_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-reliability.csv"))

  # factor-wise reliability for each stimulus
  for (letter in stimuli_letters){
    the_data <- filter(grp_data, stimulus == letter)
    stimulus_factor_data <- the_data %>% select(all_of(unlist(Readability_factors[[factor]])))
    
    # omega
    nb_obs <- nrow(stimulus_factor_data)
    corrM <- make_corrM(stimulus_factor_data, nb_fa = 1)
    om <- omega(corrM, n.obs = nb_obs, 1)
    
    # alpha
    alpha_values <- psych::alpha(stimulus_factor_data)
    
    # output df
    factor_stimulus_alpha_df <- alpha_values$total
    factor_stimulus_alpha_df$omega_tot <- om$omega.tot
    write.csv(factor_stimulus_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-",letter,"-reliability.csv", sep =""))
  }
}

```

```{r reliability of each sub-scale (each factor) for model_3}
setwd(my_wd)

cat("\n\n==========================================\n")
cat("==========================================\n")
cat("==========================================\n")
cat("\n \n MODEL 3 \n \n")
cat("==========================================\n")
cat("==========================================\n")
cat("==========================================\n\n")

this_model <- "Model_3"
## best items selected on mixed rankings between factor loadings and reliabilit measures
Readability_factors <- list(
  understand = list("obvious","understandEasi","represent"),
  layout = list("messi", "crowd","organiz"),
  dataRead = list("find","identifi","inform"),
  dataFeat = list("visibl","see")
)

# Create a vector of column names to keep for the model with selected items
columns_to_keep <- unlist(Readability_factors)

#corr Matrix with selected items
data_reduced_factors <- data %>% select(all_of(columns_to_keep))

corrM <- make_corrM(data_reduced_factors, nb_fa = 4)

num_items <- ncol(data_all_factors)
## as csv
write.csv(corrM,file=paste("generatedData-CFA/correlations/factor-", this_model, "-selected_items-corr.csv", sep =""))
# as pdf
this_file <- paste("generatedPlots-CFA/correlations/factor-", this_model,"-selected_items-corr.pdf", sep="")
pdf(this_file, height=15, width=15)
plot <- corrplot(corrM,
        # type = 'lower', #only lower half
        tl.srt = 30, #rotate text labels
        method="color",
        col = COL2('RdYlBu'),
        order="original",
        addrect = 4,
        tl.col="black", tl.cex = 1.3, # Text label color and size
        addCoef.col = "white", number.cex = 1, # Add coefficient of correlation and size
        )
dev.off()

## Create the model from list Readability_factors
# Apply the function to each element of the list
formatted_strings <- sapply(names(Readability_factors), function(factor_name) {
  factor_to_string(factor_name, Readability_factors[[factor_name]])
})

# Combine the strings into a single string
model_string <- paste(formatted_strings, collapse = '\n')

# Print the final string
cat(model_string)


for (factor in names(Readability_factors)){
  cat(paste("\n ======================\n Individual factor reliability on selected items for", this_model, "-", factor, "\n (omega and alpha) \n"))
  factor_data <- data %>% select(all_of(unlist(Readability_factors[[factor]])))
  
  # reliability
  
  # omega
  nb_obs <- nrow(factor_data)
  corrM <- make_corrM(factor_data, nb_fa = 1)
  om <- omega(corrM, n.obs = nb_obs, 1) #https://personality-project.org/r/psych/HowTo/omega.pdf
  summary(om)

  # alpha
  alpha_values <- psych::alpha(factor_data)
  cat("Alpha raw:")
  print(alpha_values$total$raw_alpha)
  print(alpha_values$total)

  # output df
  factor_alpha_df <- alpha_values$total
  factor_alpha_df$omega_tot <- om$omega.tot
  write.csv(factor_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-reliability.csv"))

  # factor-wise reliability for each stimulus
  for (letter in stimuli_letters){
    the_data <- filter(grp_data, stimulus == letter)
    stimulus_factor_data <- the_data %>% select(all_of(unlist(Readability_factors[[factor]])))
    
    # omega
    nb_obs <- nrow(stimulus_factor_data)
    corrM <- make_corrM(stimulus_factor_data, nb_fa = 1)
    om <- omega(corrM, n.obs = nb_obs, 1)
    
    # alpha
    alpha_values <- psych::alpha(stimulus_factor_data)
    
    # output df
    factor_stimulus_alpha_df <- alpha_values$total
    factor_stimulus_alpha_df$omega_tot <- om$omega.tot
    write.csv(factor_stimulus_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-",letter,"-reliability.csv", sep =""))
  }
}

```

```{r reliability of each sub-scale (each factor) for final model}
setwd(my_wd)

cat("\n\n==========================================\n")
cat("==========================================\n")
cat("==========================================\n")
cat("\n \n FINAL MODEL \n \n")
cat("==========================================\n")
cat("==========================================\n")
cat("==========================================\n\n")


this_model <- "Model_final" # = model 3
## best items selected after IRT
Readability_factors <- list(
  understand = list("obvious","represent","understandEasi"),
  layout = list("messi", "crowd","distract"),
  dataRead = list("inform","identifi","find"),
  dataFeat = list("visibl","see")
)

# Create a vector of column names to keep for the model with selected items
columns_to_keep <- unlist(Readability_factors)

#corr Matrix with selected items
data_reduced_factors <- data %>% select(all_of(columns_to_keep))

corrM <- make_corrM(data_reduced_factors, nb_fa = 4)

num_items <- ncol(data_all_factors)
## as csv
write.csv(corrM,file=paste("generatedData-CFA/correlations/factor-", this_model, "-selected_items-corr.csv", sep =""))
# as pdf
this_file <- paste("generatedPlots-CFA/correlations/factor-", this_model,"-selected_items-corr.pdf", sep="")
pdf(this_file, height=15, width=15)
plot <- corrplot(corrM,
        # type = 'lower', #only lower half
        tl.srt = 30, #rotate text labels
        method="color",
        col = COL2('RdYlBu'),
        order="original",
        addrect = 4,
        tl.col="black", tl.cex = 1.3, # Text label color and size
        addCoef.col = "white", number.cex = 1, # Add coefficient of correlation and size
        )
dev.off()

## Create the model from list Readability_factors
# Apply the function to each element of the list
formatted_strings <- sapply(names(Readability_factors), function(factor_name) {
  factor_to_string(factor_name, Readability_factors[[factor_name]])
})

# Combine the strings into a single string
model_string <- paste(formatted_strings, collapse = '\n')

# Print the final string
cat(model_string)


for (factor in names(Readability_factors)){
  cat(paste("\n ======================\n Individual factor reliability on selected items for", this_model, "-", factor, "\n (omega and alpha) \n"))
  factor_data <- data %>% select(all_of(unlist(Readability_factors[[factor]])))
  
  # reliability
  
  # omega
  nb_obs <- nrow(factor_data)
  corrM <- make_corrM(factor_data, nb_fa = 1)
  om <- omega(corrM, n.obs = nb_obs, 1) #https://personality-project.org/r/psych/HowTo/omega.pdf
  summary(om)

  # alpha
  alpha_values <- psych::alpha(factor_data)
  cat("Alpha raw:")
  print(alpha_values$total$raw_alpha)
  print(alpha_values$total)

  # output df
  factor_alpha_df <- alpha_values$total
  factor_alpha_df$omega_tot <- om$omega.tot
  write.csv(factor_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-reliability.csv"))

  # factor-wise reliability for each stimulus
  for (letter in stimuli_letters){
    the_data <- filter(grp_data, stimulus == letter)
    stimulus_factor_data <- the_data %>% select(all_of(unlist(Readability_factors[[factor]])))
    
    # omega
    nb_obs <- nrow(stimulus_factor_data)
    corrM <- make_corrM(stimulus_factor_data, nb_fa = 1)
    om <- omega(corrM, n.obs = nb_obs, 1)
    
    # alpha
    alpha_values <- psych::alpha(stimulus_factor_data)
    
    # output df
    factor_stimulus_alpha_df <- alpha_values$total
    factor_stimulus_alpha_df$omega_tot <- om$omega.tot
    write.csv(factor_stimulus_alpha_df,file=paste("generatedData-CFA/reliability/to aggregate/",factor,"-",this_model,"-",letter,"-reliability.csv", sep =""))
  }
}

```